## Lab 2 Report

### 实验环境

||||
|--------|--------------|--------------------------|
|硬件环境|CPU（vCPU数目）| 16 |
||CPU 型号 |Intel(R) Core(TM) i7-10875H CPU @ 2.30GHz|
||GPU(型号，数目)|GeForce RTX 3070 Laptop|
|软件环境|OS版本|Windows 10|
||深度学习框架<br>python包名称及版本|pytorch 1.7.1|
||CUDA版本|11.1|
||||

### 实验结果

#### 性能评测

|||||
|-|-|-|-|
| 实现方式（Linear层为例）| 性能评测 |
||epochs|平均epoch<br>训练时间|平均epoch<br>测试时间|
|PyTorch原有张量运算                                       | 14 | 8.518810 s | 1.815350 s |
|基于Python API的<br>定制化张量运算<br>(linear 层)          | 14 | 8.316190 s | 1.811434 s |
|基于C++的<br>定制化张量运算<br>(linear 层)                 | 14 | 8.887545 s | 1.908460 s |
|基于Python API的<br>定制化张量运算<br>(conv2d 层)          | 14 | 205.418139 s | 5.201738 s |
|基于C++的<br>定制化张量运算<br>(conv2d 层)                 | 14 | 190.234131 s | 5.092333 s |
|基于Python API的<br>定制化张量运算<br>(conv2d 层 im2col 法)| 14 | 109.964599 s | 3.879696 s |
||||

**分析**: 定制化的卷积运算明显慢于 **Pytorch** 自带的卷积运算, 这是可能因为其内部有一些 `for` 循环难以被优化.

但当我在前向函数(`forward`) 中使用 `im2col` 的方法后能大幅提升速度(快了一倍左右). 这里的 `im2col` 据说是 **Pytorch** 内部实现的方法. 如果将反向函数 `backward` 也改写成 `im2col` 的方法, 则预计可以达到 **Pytorch** 自身的水平. 

但由于时间有限及课内实验考试等压力, 未能完成改写 `backward` 的工作.

#### 准确度评测

||||||
|-|-|-|-|-|
| 实现方式（Linear层为例）| 准确度评测 |
||epochs| train loss | test loss | test acc |
|PyTorch原有张量运算                                       | 14 | 0.005726 | 0.0276 | 9913/10000 |
|基于Python API的<br>定制化张量运算<br>(linear 层)          | 14 | 0.054133 | 0.0271 | 9912/10000 |
|基于C++的<br>定制化张量运算<br>(linear 层)                 | 14 | 0.056000 | 0.0273 | 9914/10000 |
|基于Python API的<br>定制化张量运算<br>(conv2d 层)          | 14 | 0.001136 | 0.0272 | 9908/10000 |
|基于C++的<br>定制化张量运算<br>(conv2d 层)                 | 14 | 0.001136 | 0.0272 | 9908/10000 |
|基于Python API的<br>定制化张量运算<br>(conv2d 层 im2col 法)| 14 | 0.001478 | 0.0280 | 9911/10000 |
||||

这里的结果是符合预期的. 同样功能的代码应当给出相近的结果! 可以看出来, 各种情况下的准确度 acc 及训练和测试的误差都是比较相近的.

### 实验总结

本次实验中, 亲手实现了 Python 和 C++ 定制化 Pytorch 张量运算, 包括 `Linear` 层 和 `Conv2d` 层.

其中在 `Conv2d` 层的实现中, 我查找了大量资料, 写出了第一个版本. 其以 `for` 循环为基础进行卷积运算, 速度显然是很低的. 

而后经过一些改进, 把 for 循环整合成张量运算, 以便 Pytorch 调度 GPU 来进行优化. 这达到了上述评测的结果. 但依然没有达到 **Pytorch** 库本身的结果. 

因此又去查询 **Pytorch** 本身的实现方案, 发现它用了 `im2col` 的方法来提升卷积运算的性能. 经修改, 我将 `forward` 函数内部的 `for` 循环及相关操作改为了使用 `im2col` 的方法, 性能得到了大幅提升(1倍以上). 但由于时间有限, 未能完成 `backward` 函数的改写, 实属遗憾. 预期如果改写好 `backward` 函数, 整个卷积运算的性能将能够达到比肩 **Pytorch** 的水准.